{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a572dc",
   "metadata": {},
   "source": [
    "## KMeans clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d65749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b895656f",
   "metadata": {},
   "source": [
    "### let's get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d71f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108ebc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ae179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1843030",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "head",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'head'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: head"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe98f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366faa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5710d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame from data['data'], columns=data['feature_names']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a7494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# what data types do you have?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18482b6b",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "The scale of \"proline\" is much higher than the scale of many other variables! K-Means is a distance based algorithm: we need to scale / normalize\n",
    "\n",
    "Check out the docs for standardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "Explore other methods for normalizing data: https://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54977dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale your data with the standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9130c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of scaled features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d4008e",
   "metadata": {},
   "source": [
    "### Clustering \n",
    "\n",
    "We will pick manually the number of clusters we want - let's set it to 8. Later we will discuss how many clusters we should have.\n",
    "\n",
    "When randomness is involved, we better use a random seed so that we can reproduce our results. We can set this directly to the argument random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#define the model, fit the model to your data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca84451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the cluster centres \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting / assigning the clusters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef206ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the clusters\n",
    "pd.Series(clusters).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc41024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the cluster assignment by placing it in the original dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd5b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ad651a5",
   "metadata": {},
   "source": [
    "### Time to think : What makes a cluster a \"good\" cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48faef39",
   "metadata": {},
   "source": [
    "+ By default Scikit-Learn has tried 10 different random initializations and kept the best model- based on Inertia\n",
    "\n",
    "\n",
    "\n",
    "* **Inertia**, Intuitively, inertia tells how far away the points within a cluster are. Therefore, a small of inertia is aimed for. The range of inertiaâ€™s value starts from zero and goes up.\n",
    "\n",
    "* **Silhouette score**, (discuss later), -1 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ec48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total inertia of all the centroids\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca508d4",
   "metadata": {},
   "source": [
    "### other parameters \n",
    "\n",
    "max_iter: model iterates up to 300 times by default (those are the re-computing centroids iterations we saw earlier)\n",
    "\n",
    "tol: determine when to stop iterating (if the clusters have changed only veeeery slightly, we assume we have achieved 'convergence')\n",
    "\n",
    "algorithm: There are variations in the implementation of most algorithms and K-Means is no exception. By default, we're using a 'smart' implementation called elkan.\n",
    "\n",
    "## Activity \n",
    "- For learning purposes, we can tweak the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a77b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with the KMeans parameters and see how that affects the 'inertia' result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af725d8",
   "metadata": {},
   "source": [
    "### Finding the optimal number of clusters\n",
    "We have used K=8 by default for now - but we know that 8 might not be the optimal numbner of clusters for our dataset. Having a metric like inertia, we can compute it for several K values and then use the \"elbow method\" to choose the best K.\n",
    "\n",
    "We will now leave all other parameters with their default value, since it seems to work pretty well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to run Kmeans with all values of K, from 2 to 20\n",
    "K = range(2, 20)\n",
    "\n",
    "# For each model, store the inertia in a list\n",
    "inertia = []\n",
    "\n",
    "for ...\n",
    "\n",
    "\n",
    "print(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75334bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, inertia, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "plt.title('Elbow Method showing the optimal k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eff4a4",
   "metadata": {},
   "source": [
    "Findings: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34396881",
   "metadata": {},
   "source": [
    "+ **Inertia** is the metric that Scikit-Learn optimizes, but it does not have a limited range and that makes it difficult to evaluate.\n",
    "\n",
    "\n",
    "\n",
    "+ There's another metric called **Silhouette Score**\n",
    "* what Silhouette score does: **how similar is an observation to its own cluster compared to other clusters**\n",
    "* $S_i = \\frac{(b_i - a_i)}{\\text{max}(a_i,b_i)}$\n",
    "    * `a`: mean intra-cluster distance (the average distance between the i-th observation and every other observation in the cluster where i belongs to)\n",
    "    * `b`: the mean **nearest** inter cluster distance (the average distance between the i_th observation of the nearest cluster that i is **not part of**)\n",
    "    \n",
    "* The **silhouette score for the whole model** is the **average** of all the silhouette scores of each instance.\n",
    "\n",
    "Well separated clusters:\n",
    "* `a` - the mean intra cluster distance is relatively small compared to\n",
    "* `b` - the mean inter cluster distance that the points are not part of\n",
    "* that means $S = (b - a) / max(a,b)$ approaches 1\n",
    "\n",
    "Not so well separated clusters:\n",
    "* `a` - the mean intra cluster distance is not so small (relatively) compared to\n",
    "* `b` - the mean inter cluster distance that the points are not part of\n",
    "* that means $S = (b - a) / max(a,b)$ becomes smaller and smaller (approaches 0 when b=a)\n",
    "* S becomes negative for a point, which is not (yet) in the right cluster (too less iterations? play with tolerance. Or random effect - increase n_init?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878869f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "K = range(2, 20)\n",
    "\n",
    "silhouettes = []\n",
    "\n",
    "for ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, silhouettes, 'bo-')\n",
    "plt.xlabel('k (number of clusters)')\n",
    "plt.xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "plt.ylabel('silhouette score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77098937",
   "metadata": {},
   "source": [
    "Findings: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599e997",
   "metadata": {},
   "source": [
    "# What next?\n",
    "\n",
    "It's the moment to perform clustering on the songs you collected. Remember that the ultimate goal of this project is to improve the recommendations of songs. Clustering the songs will allow the recommendation system to limit the scope of the recommendations to only songs that belong to the same cluster - songs with similar audio features.\n",
    "\n",
    "The experiments you did with the Spotify API and the Billboard web scraping will allow you to create a pipeline such that when the user enters a song, you:\n",
    "\n",
    "+ 1. Check whether or not the song is in the Billboard Hot 100.\n",
    "    + 1.1. If the song is in the Billboard Hot 100, recommend another song from there.\n",
    "    + 1.2. If the song is not in the Billboard Hot 100, skip to step 2.\n",
    "    \n",
    "+ 2. Collect the audio features from that song by sending a requesto to the Spotify API.\n",
    "\n",
    "+ 3. \"Predict\" the cluster of the song.\n",
    "\n",
    "+ 4. Pick a random song from the predicted cluster and give it back to the user.\n",
    "\n",
    "We want to make sure that clusters make some sense. Besides tuning the parameters of the K-Means algorithm, the most important measure of \"performance\" is checking whether or not the recommendations given make some sense to you and your classmates - so test and tune before demonstrating your new recommender product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226349a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
